{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "#rom PIL import Image\n",
    "img = Image.open('Test/apple/4.jpeg')\n",
    "img = load_img('imagePath')  # this is a PIL image\n",
    "img.save('saveImagePath')\n",
    "plt.imshow(img)\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 128, 128)\n",
    "x = x.reshape((1,) + x.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification on Small-scale Image Data based on Data Expansion/Augmentation\n",
    "Created on Wed Nov 09 22:25:36 2016\n",
    "Edit history:\n",
    "  11/20/2016: add early stopping and modelcheckpoint  \n",
    "  11/22/2016: data splitting of 80% training and 20% testing\n",
    "  Three training cases: \n",
    "      1) 100 epochs\n",
    "      2) 200 epochs\n",
    "      3) 400 epochs\n",
    "      4) 600 epochs\n",
    "  Obtained best accuracies\n",
    "      1): 83.37% for training and 87.24% for testing\n",
    "      2): 87.24% for training and 89.21% for testing\n",
    "      3): 90.34% for training and 90.41% for testing\n",
    "      4): 93.08% for training and 89.98% for testing\n",
    "  \n",
    "\"\"\"\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "#from PIL import Image\n",
    "#img = Image.open('Test/apple/4.jpeg')\n",
    "img = load_img('imagePath')  # this is a PIL image\n",
    "img.save('saveImagePath')\n",
    "plt.imshow(img)\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 128, 128)\n",
    "x = x.reshape((1,) + x.shape) \n",
    "\n",
    "###############################################################################\n",
    "#                            Prepare data sets                                #\n",
    "###############################################################################\n",
    "#Split images into training and testing parts\n",
    "#Note: run only one time!!\n",
    "def splitImageSet(rootFolder, outFolder, p):\n",
    "    import os\n",
    "    from os import listdir\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    cats = listdir(rootFolder) # a list of subfolder names    \n",
    "    for cat in cats:\n",
    "        print 'Image Category...{}'.format(cat)\n",
    "        \n",
    "        folderPath = (os.path.join(rootFolder,cat))\n",
    "        imgNames = listdir(folderPath)\n",
    "        imgPaths = [os.path.join(folderPath,imgName) for imgName in imgNames]\n",
    "        idx = np.random.permutation(len(imgPaths))\n",
    "        trainIdx = idx[:int(p*len(idx))]\n",
    "        testIdx = [ind for ind in idx if not ind in trainIdx]\n",
    "\n",
    "        if not os.path.exists(os.path.join(outFolder,'Train',cat)):\n",
    "            os.makedirs(os.path.join(outFolder,'Train',cat))\n",
    "        for k in range(len(trainIdx)):\n",
    "            img = Image.open(os.path.join(imgPaths[trainIdx[k]]))\n",
    "            #temp = os.path.join(outFolder,'train',cat,imgNames[trainIdx[k]])\n",
    "            img.save(os.path.join(outFolder,'Train',cat,imgNames[trainIdx[k]]))            \n",
    "        if not os.path.exists(os.path.join(outFolder,'Test',cat)):\n",
    "            os.makedirs(os.path.join(outFolder,'Test',cat))\n",
    "        for k in range(len(testIdx)):\n",
    "            img = Image.open(os.path.join(imgPaths[testIdx[k]]))\n",
    "            img.save(os.path.join(outFolder,'Test',cat,imgNames[testIdx[k]])) \n",
    "            \n",
    "    print 'Split Done!'\n",
    "    return\n",
    "rootFolder = 'rootFolder' #add the image directory\n",
    "outFolder = 'outFolder' #image output directory    \n",
    "splitImageSet(rootFolder, outFolder, 0.80)    \n",
    "\n",
    "#Please start from here!!\n",
    "###############################################################################\n",
    "#                           Build a CNN model                                 #\n",
    "###############################################################################\n",
    "#CNN model\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, History\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 7, 7, input_shape=(3, 128, 128)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) #initial lr = 0.01\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "print model.summary()\n",
    "\n",
    "####################################\n",
    "#         Callback Schedule       #\n",
    "###################################\n",
    "import keras\n",
    "class decaylr_loss(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(decaylr_loss, self).__init__()\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        #loss=logs.items()[1][1] #get loss\n",
    "        loss=logs.get('loss')\n",
    "        print \"loss: \",loss\n",
    "        old_lr = 0.001 #needs some adjustments\n",
    "        new_lr= old_lr*np.exp(loss) #lr*exp(loss)\n",
    "        print \"New learning rate: \", new_lr\n",
    "        K.set_value(self.model.optimizer.lr, new_lr)\n",
    "lrate = decaylr_loss()\n",
    "#early stopping\n",
    "patience = 20\n",
    "earlystopper = EarlyStopping(monitor='val_acc', patience=patience, \n",
    "                             verbose=1, mode='max')       \n",
    "#check point\n",
    "wdir = 'wdir' #work directory\n",
    "filepath = os.path.join(wdir,'modelWeights','cnnModelDEp80weights.best.hdf5') #save model weights\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "###############################################################################\n",
    "#                     Data Expansion or Augmentation                          #\n",
    "###############################################################################\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                   #featurewise_center=True,\n",
    "                                   #featurewise_std_normalization=True,\n",
    "                                   rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "trainDir = 'Data\\Train'\n",
    "train_generator = train_datagen.flow_from_directory(trainDir,  \n",
    "                                                    target_size=(128,128),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "testDir = 'Data\\Test'\n",
    "test_generator = test_datagen.flow_from_directory(testDir,\n",
    "                                                  target_size=(128,128),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "###############################################################################\n",
    "##                      Fit, Evaluate and Save Model                          #                                  \n",
    "###############################################################################\n",
    "epochs = 100\n",
    "#epochs = 200\n",
    "#epochs = 400\n",
    "#epochs = 600\n",
    "samples_per_epoch = 4654 \n",
    "val_samples = 1168\n",
    "\n",
    "#Fit the model\n",
    "hist = History()\n",
    "model.fit_generator(train_generator,\n",
    "                    samples_per_epoch= samples_per_epoch,\n",
    "                    nb_epoch=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=test_generator,\n",
    "                    nb_val_samples=val_samples, \n",
    "                    callbacks = [earlystopper, lrate, checkpoint, hist])\n",
    "\n",
    "#evaluate the model\n",
    "scores = model.evaluate_generator(test_generator, val_samples=val_samples) \n",
    "print(\"Accuracy = \", scores[1])\n",
    "\n",
    "#save model\n",
    "savePath = wdir\n",
    "model.save_weights(os.path.join(savePath,'cnnModelDEp80.h5')) # save weights after training or during training\n",
    "model.save(os.path.join(savePath,'cnnModelDEp80.h5')) #save complied model\n",
    "\n",
    "#plot acc and loss vs epochs\n",
    "import matplotlib.pyplot as plt\n",
    "print(hist.history.keys())\n",
    "#accuracy\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig(os.path.join(savePath,'cmdeP80AccVsEpoch.jpeg'), dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n",
    "#loss\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.savefig(os.path.join(savePath,'cmdeP80LossVsEpoch.jpeg'), dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################                          \n",
    "#Note: train 4364 images (80%) and test 1458 images (20%)                     # \n",
    "# 100 epochs:                                                                 #\n",
    "# 200 epoches: acc = 0.8724; val_acc = 0.89212                                #  \n",
    "# 400 epoches:                                                                #\n",
    "# 600 epochs:                                                                 #\n",
    "###############################################################################\n",
    "\n",
    "# load the model\n",
    "# not necessary the best at the end of training \n",
    "from keras.models import load_model\n",
    "myModel = load_model(os.path.join(savePath,'cnnModelDEp80.h5'))                                  \n",
    "scores = myModel.evaluate_generator(test_generator,val_samples)\n",
    "print(\"Accuracy = \", scores[1])\n",
    "\n",
    "########################\n",
    "# Check-pointed model  #\n",
    "#######################\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 7, 7, input_shape=(3, 128, 128)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 5, 5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#lr = 0.00277615583366 #adjust lr based on training process\n",
    "#lr = 0.00181503843077\n",
    "#lr = 0.00163685841542 #case 2\n",
    "lr =  0.00122869861281 # case3\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True) \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "model.load_weights(filepath) #load saved weights\n",
    "scores = model.evaluate_generator(test_generator,val_samples)\n",
    "print(\"Accuracy = \", scores[1])\n",
    "\n",
    "\n",
    "#Confusion matrix on the test images\n",
    "#imgDir = testDir\n",
    "imgDir = trainDir\n",
    "test_generator = test_datagen.flow_from_directory(imgDir,\n",
    "                                                  target_size=(128,128),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False, \n",
    "                                                  class_mode='categorical')\n",
    "#val_samples = 1168\n",
    "val_samples = 4654\n",
    "predict = model.predict_generator(test_generator,val_samples)\n",
    "\n",
    "yTrue = test_generator.classes\n",
    "yTrueIdx = test_generator.class_indices\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "yHat = np.ones(predict.shape[0],dtype = int)\n",
    "for i in range(predict.shape[0]):\n",
    "    temp = predict[i,:]\n",
    "    yHat[i] = np.argmax(temp)  \n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(yTrue,yHat)\n",
    "print \"Accuracy on test images:\", acc #same as scores[1]\n",
    "\n",
    "def numToLabels(y,cat):\n",
    "    numLabel = []\n",
    "    import numpy as np\n",
    "    yNew = np.unique(y) #sorted \n",
    "    for i in range(len(y)):\n",
    "        idx = np.where(yNew == y[i])[0][0]\n",
    "        numLabel.append(cat[idx])\n",
    "    return numLabel                   \n",
    "#labels = sorted(yTrueIdx.keys())\n",
    "labels = ['Ap','Ba','Br','Bu','Eg','Fr','Hd','Pz','Rc','St']\n",
    "yActLabels = numToLabels(yTrue,labels)\n",
    "yHatLabels = numToLabels(yHat,labels)\n",
    "CM = confusion_matrix(yActLabels,yHatLabels,labels) #np.array\n",
    "#print CM    \n",
    "print(classification_report(yTrue,yHat,target_names=labels))\n",
    "\n",
    "#Alternatively: pd.crosstab\n",
    "import pandas as pd\n",
    "#preds = pd.DataFrame(predict)\n",
    "y1 = pd.Categorical(yActLabels,categories=labels)\n",
    "y2 = pd.Categorical(yHatLabels,categories=labels)\n",
    "pd.crosstab(y1,y2,rownames=['True'], colnames=['Predicted'])\n",
    "\n",
    "###############################################################################\n",
    "#                                Miscellaneous                                #\n",
    "###############################################################################  \n",
    "#evaluate execution efficiency\n",
    "import time\n",
    "t = time.time()\n",
    "s = model.predict_generator(test_generator,val_samples)\n",
    "elapsedTime = time.time()-t\n",
    "print 'Average time: {} second'.format(elapsedTime/val_samples)\n",
    "#average time: 0.00895 s, less than 0.01 s\n",
    "def getImgPaths2(rootPath): \n",
    "    import os\n",
    "    from os import listdir\n",
    "    print 'Extract paths and labels...'\n",
    "    cats = listdir(rootPath)\n",
    "    imgPaths = []\n",
    "    imgLabels = []\n",
    "    for cat in cats:\n",
    "        print '{}...'.format(cat)\n",
    "        foldPaths = os.path.join(rootPath, cat)\n",
    "        imgPaths.extend([os.path.join(foldPaths,imgName) for imgName in listdir(foldPaths)])\n",
    "        imgLabels.extend([cat]*len(listdir(foldPaths)))\n",
    "    return imgPaths, imgLabels \n",
    "def getImgData(imgPaths):\n",
    "    from scipy import misc \n",
    "    import numpy as np\n",
    "    print('Extract image data...')\n",
    "    temp1 = misc.imread(imgPaths[0])\n",
    "    imgData = np.zeros((len(imgPaths),temp1.shape[0],temp1.shape[1],temp1.shape[2]),\n",
    "                       dtype='float32')\n",
    "    for ii in range(len(imgPaths)):\n",
    "        temp = misc.imread(imgPaths[ii])\n",
    "        imgData[ii,:,:,:] = temp\n",
    "        print \"\\r{} Percent complete\\r\".format(100*(ii+1)/len(imgPaths)),\n",
    "    return imgData\n",
    "imgPaths = getImgPaths2(trainDir)    \n",
    "# Expanded image data\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow()\n",
    "plt.imshow()\n",
    "\n",
    "#######################################################\n",
    "#   Images with correct or wroning predicted Labels   #\n",
    "####################################################### \n",
    "imgPaths, imgLabels = getImgPaths2(testDir)\n",
    "X_test = getImgData(imgPaths) #(1168, 128, 128, 3)\n",
    "X_test /= 255\n",
    "test_wrong = [im for im in zip(X_test, yHatLabels, yActLabels) if im[1] != im[2]]\n",
    "print(len(test_wrong))\n",
    "#112 misclassified images\n",
    "\n",
    "#show some misclassified images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 8))\n",
    "import numpy as np\n",
    "for ind, val in enumerate(test_wrong):\n",
    "    #print ind\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    plt.subplot(7, 8, ind + 1)\n",
    "    img = val[0]\n",
    "    img *= 255\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(0,0,val[2], fontsize=12, color='blue')\n",
    "    plt.text(40,0,val[1], fontsize=12, color='red')\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    if ind==55:\n",
    "        break     \n",
    "plt.savefig(os.path.join(savePath,'MissClassifiedImages1.jpeg'), \n",
    "            dpi=800, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#show some misclassified images\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 8))\n",
    "import numpy as np\n",
    "for ind, val in enumerate(test_wrong[56:]):\n",
    "    #print ind\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    plt.subplot(7, 8, ind + 1)\n",
    "    img = val[0]\n",
    "    img *= 255\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(0,0,val[2], fontsize=12, color='blue')\n",
    "    plt.text(40,0,val[1], fontsize=12, color='red')\n",
    "    plt.imshow(img.astype('uint8'))\n",
    "    if ind==55:\n",
    "        break     \n",
    "plt.savefig(os.path.join(savePath,'MissClassifiedImages2.jpeg'), \n",
    "            dpi=800, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "########################################\n",
    "#   Rotated, shifted, sheared Images   #\n",
    "########################################\n",
    "imgData = getImgData(imgPaths[:9]) #extract 9 images, (9L, 128L, 128L, 3L)\n",
    "# plot raw images\n",
    "for i in range(0, 9):\n",
    "    from scipy import misc\n",
    "    img = misc.imread(imgPaths[i])\n",
    "    plt.subplot(3,3,i+1)\n",
    "    fig = plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    #ax.set_axis_off()\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "plt.show()\n",
    "#or\n",
    "for i in range(0, 9):\n",
    "    img = imgData[i,:,:,:].astype('uint8')\n",
    "    plt.subplot(3,3,i+1)\n",
    "    fig = plt.imshow(img)\n",
    "    ax = plt.gca()\n",
    "    ax.set_axis_off()\n",
    "plt.savefig(os.path.join(savePath,'RawImages.jpeg'), dpi=1000, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#image distortion by ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator #, array_to_img, img_to_array\n",
    "datagen = ImageDataGenerator(\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True\n",
    "                             )\n",
    "#single fruit\n",
    "#from PIL import Image\n",
    "x = imgData[1].reshape((1,)+imgData[0].shape)\n",
    "fig = plt.imshow(imgData[1].astype('uint8')) #imshow: img_dim_ordering (w,h,channels)\n",
    "plt.gca().set_axis_off()\n",
    "plt.savefig(os.path.join(savePath,'rawImage.jpeg'), \n",
    "            dpi=1000, bbox_inches='tight')\n",
    "x = x.transpose(0,3,1,2) #reshaped into 4d for datagen.flow \n",
    "i = 0\n",
    "for x_batch in datagen.flow(x, batch_size=1):\n",
    "    i += 1\n",
    "    plt.subplot(3,3,i)\n",
    "    I = x_batch[0]\n",
    "    img = (I.transpose(1,2,0)).astype('uint8')\n",
    "    fig=plt.imshow(img,cmap=plt.get_cmap('gray'))\n",
    "    plt.gca().set_axis_off()\n",
    "    if i==9:\n",
    "        break\n",
    "plt.savefig(os.path.join(savePath,'expandedImages1.jpeg'), \n",
    "            dpi=1000, bbox_inches='tight')\n",
    "#multiple fruit\n",
    "for x_batch in datagen.flow(imgData.transpose(0,3,1,2), batch_size=9):\n",
    "    for i in range(0,9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        I = x_batch[i]\n",
    "        #img = array_to_img(I)\n",
    "        img = (I.transpose(1,2,0)).astype('uint8')\n",
    "        fig = plt.imshow(img,cmap=plt.get_cmap('gray'))\n",
    "        plt.gca().set_axis_off()\n",
    "    plt.show()\n",
    "    break\n",
    "plt.savefig(os.path.join(savePath,'expandedImages2.jpeg'), \n",
    "            dpi=1000, bbox_inches='tight')\n",
    "  \n",
    "#evaluate execution efficiency\n",
    "import time\n",
    "t = time.time()\n",
    "s = model.predict_generator(test_generator,val_samples)\n",
    "elapsedTime = time.time()-t\n",
    "print 'Average time: {} second'.format(elapsedTime/val_samples)\n",
    "#average time: 0.00895 s, less than 0.01 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
